<!DOCTYPE HTML>
<html>
<head>

<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1" />

<title>Alt.Net Archaeologist</title>
</head>

<body>
  <h1>Alt.Net Archaeologist</h1>
  <a href="/">back home</a>
  <h3>What is this?</h3>
  <p>
    This is an experimental project that attempts to make it easier for programming conference participants to collect artifacts from their experiences. Ideally, when the conference is over the conference data will be openly mined, analyzed, and edited by anyone. Also, it should be easy to add citations and provide acknowledgements to help fill in the gaps of who participated but did so in a way we couldn't automatically aggregate.
  </p>
  <p>
    Think of it as a decentralized wiki of sorts.
  </p>

  <h3>Why?</h3>
  <p>
    We already try to do this but in very incomplete ways. Conference wikis, organization sites, etc... they all try to solve the problem of gathering the aggregate knowledge and experiences of conference attendees by having attendees use a centralized system. The problem then arises that there is too much friction to update this centralized system and so few do.
  </p>
  <p>
    The solution lies in allowing the conference attendees to document the conference in any way they see fit and place the burden of aggregation on the centralized service.
  </p>
  <h3>How Can I Help?</h3>
  <p>
    Currently this is a project supported entirely by one person so there are PLENTY of areas where help could be used (basically everything). Contact the project author to collaborate.
  </p>
  <h3>Project Author</h3>
  <p>
    The project was created and is maintained by <a href="http://codelikebozo.com">Justin Bozonier</a>.
    <ul>
      <li>Tweet: <a href="http://twitter.com/darkxanthos">@darkxanthos</a></li>
      <li>Email/IM: darkxanthos at gmail dot com</li>
    </ul>
  </p>
  <h3>Tech Pr0n (What Runs This Thing?!)</h3>
  <p>
    Currently all of the tweets are mined using Twitter's search api looking for certain hash tags. The service that does this is hosted on a Rackspace Cloud server running Ubuntu Linux. The mined tweets are then saved to a MongoDB instance hosted by MongoHQ. The site you are currently viewing then shows views of that data. It is hosted on Heroku and built atop Ruby/Sinatra and just uses the MongoDB Ruby driver for data access.
  </p>
  <p>
    Some next steps will entail running multiple services on the Ubuntu server to drill further into the data and record associations. For example, another datasource I have for Alt.Net 2011 is the attendee registration report. Using that I can provide some richer information regarding the participants. Also, when participants link to blogs and images, there will be another service to pull and archive that data as well.
  </p>
  <p>
    There will be two main groups of data services: Discovery services and analytical services.
  </p>
  <p>
    The discovery services principle roles are to record the events occuring in the real world. They will not change the data but merely aggregate it exactly as they found it. Their role is merely discovering the data that exists
  </p>
  <p>
    The analytical services will work to analyze the data in the discovery services. The important distinction here is that none of the data generated by the analytical services needs to be saved because it will all be able to be rebuilt from the discovery services.
  </p>
</body>
</html>